"""
transaction_web_app.py

This Streamlit application provides a simple user interface for
uploading credit card statements in PDF or image (screenshot) format,
extracting transaction data, automatically assigning categories based on
keyword rules, and allowing the user to review and adjust categories.

The app assumes that the user has installed the following Python
packages in their environment:

* streamlit ‚Äî for building the web interface
* pandas ‚Äî for data manipulation
* pdfplumber ‚Äî for reading table data from PDF files
* pytesseract ‚Äî for Optical Character Recognition on images
* Pillow (PIL) ‚Äî for image handling

You also need to have the Tesseract OCR engine installed on your
system for pytesseract to work.

Usage: run this app with

    streamlit run transaction_web_app.py
"""

import io
import os
import re
from datetime import datetime
from typing import Dict, List, Optional

import pandas as pd
import streamlit as st

try:
    import pdfplumber  # type: ignore
except ImportError:
    pdfplumber = None

try:
    import pytesseract  # type: ignore
    from PIL import Image
except ImportError:
    pytesseract = None
    Image = None


def extract_transactions_from_pdf(file_stream: io.BytesIO) -> pd.DataFrame:
    """Extract transactions from a PDF statement using pdfplumber.

    Assumes the PDF contains a table with columns Date, Description and
    Amount.  This function looks for the largest table on the first few
    pages.  It may need adaptation for your specific statement layout.
    """
    if pdfplumber is None:
        raise RuntimeError("pdfplumber is not installed; please install it to process PDFs.")

    transactions = []
    with pdfplumber.open(file_stream) as pdf:
        for page in pdf.pages[:5]:
            tables = page.extract_tables()
            for table in tables:
                if len(table) > 1 and len(table[0]) >= 3:
                    header = [h.strip().lower() for h in table[0]]
                    try:
                        date_idx = header.index("date")
                        desc_idx = header.index("description")
                        amt_idx = header.index("amount")
                    except ValueError:
                        continue
                    for row in table[1:]:
                        try:
                            date = datetime.strptime(row[date_idx].strip(), "%d/%m/%Y")
                        except Exception:
                            try:
                                date = datetime.strptime(row[date_idx].strip(), "%Y-%m-%d")
                            except Exception:
                                continue
                        description = row[desc_idx].strip()
                        try:
                            amount = float(row[amt_idx].replace(",", ""))
                        except Exception:
                            continue
                        transactions.append({"date": date, "description": 
description, "amount": amount})
            if transactions:
                break
    if not transactions:
        raise RuntimeError("No transaction table detected in the uploaded PDF.")
    df = pd.DataFrame(transactions)
    return df


def extract_transactions_from_image(file_stream: io.BytesIO) -> pd.DataFrame:
    """Extract transactions from an image using OCR.

    This function reads the entire image as text and then attempts to
    parse lines that contain a date, description and amount.  It is
    simplistic and may need refinement for real statement layouts.  If
    pytesseract is not available, an error is raised.
    """
    if pytesseract is None or Image is None:
        raise RuntimeError(
            "pytesseract or PIL is not installed; please install them and ensure tesseract is available."
        )
    image = Image.open(file_stream)
    text = pytesseract.image_to_string(image)
    lines = text.splitlines()
    pattern = re.compile(r"(\\d{2}/\\d{2}/\\d{4})\\s+(.+?)\\s+(-?\\d+[.,]?\\d*)")
    records = []
    for line in lines:
        match = pattern.search(line)
        if match:
            date_str, desc, amt_str = match.groups()
            try:
                date = datetime.strptime(date_str, "%d/%m/%Y")
            except Exception:
                continue
            amount = float(amt_str.replace(",", ""))
            records.append({"date": date, "description": desc.strip(), 
"amount": amount})
    if not records:
        raise RuntimeError(
            "No transactions detected in the image.  Ensure the statement is clearly legible and try again."
        )
    df = pd.DataFrame(records)
    return df



def translate_japanese_to_english_ai(text: str, api_key: str = None) -> str:
    """Translate Japanese text to English using OpenAI GPT-3.5-turbo for high accuracy."""
    try:
        import openai
        
        # Check if text contains Japanese characters
        if not text or not any(ord(char) > 127 for char in text):
            return text
        
        # If no API key provided, try to get from environment
        if not api_key:
            api_key = os.getenv('OPENAI_API_KEY')
        
        if not api_key:
            st.warning("No OpenAI API key found. Using free translation fallback.")
            return translate_japanese_to_english_fallback(text)
        
        # Configure OpenAI client
        client = openai.OpenAI(api_key=api_key)
        
        # Create translation prompt
        prompt = f"""
        Translate the following Japanese text to English. This is from a credit card statement, so maintain accuracy for financial terms and merchant names.
        
        Japanese text: {text}
        
        English translation:"""
        
        # Get translation from GPT-3.5-turbo
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a professional translator specializing in financial documents. Translate Japanese to English accurately, especially for merchant names and financial terms."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=100,
            temperature=0.1  # Low temperature for consistent translations
        )
        
        translated = response.choices[0].message.content.strip()
        return translated
        
    except Exception as e:
        st.warning(f"AI translation failed for '{text}': {e}")
        # Fallback to free translation
        return translate_japanese_to_english_fallback(text)

def translate_japanese_to_english_fallback(text: str) -> str:
    """Fallback translation using deep-translator when AI translation fails."""
    try:
        from deep_translator import GoogleTranslator
        if text and any(ord(char) > 127 for char in text):
            translated = GoogleTranslator(source='ja', target='en').translate(text)
            return translated
        return text
    except Exception as e:
        st.warning(f"Fallback translation failed for '{text}': {e}")
        return text

def translate_japanese_to_english(text: str, mode: str = "Free Fallback", api_key: str = None) -> str:
    """Main translation function - handles different translation modes."""
    if mode == "AI-Powered (GPT-3.5)":
        return translate_japanese_to_english_ai(text, api_key)
    elif mode == "Free Fallback":
        return translate_japanese_to_english_fallback(text)
    else:  # No Translation
        return text

def extract_transactions_from_csv(file_stream: io.BytesIO, translation_mode: str = "Free Fallback", api_key: str = None) -> pd.DataFrame:
    """Extract transactions from a CSV file.
    
    This function reads CSV files and attempts to identify date, description, and amount columns.
    It handles common CSV formats from different banks and financial institutions.
    Now includes Japanese translation support.
    """
    try:
        # Try to read the CSV with different encodings
        df = pd.read_csv(file_stream, encoding='utf-8')
    except UnicodeDecodeError:
        file_stream.seek(0)  # Reset file pointer
        df = pd.read_csv(file_stream, encoding='latin-1')
    
    # Common column names for different banks (including Japanese)
    date_columns = ['date', 'transaction_date', 'posting_date', 'date_posted', 'transaction date',
                    'Âà©Áî®Êó•', 'ÂèñÂºïÊó•', 'Ê±∫Ê∏àÊó•']
    desc_columns = ['description', 'merchant', 'payee', 'transaction_description', 'details',
                    'Âà©Áî®Â∫óÂêç„ÉªÂïÜÂìÅÂêç', 'Â∫óËàóÂêç', 'ÂïÜÂìÅÂêç', 'ÂèñÂºïÂÜÖÂÆπ']
    amount_columns = ['amount', 'debit', 'credit', 'transaction_amount', 'amount_debited', 'amount_credited',
                      'Âà©Áî®ÈáëÈ°ç', 'ÊîØÊâïÈáëÈ°ç', 'ÂèñÂºïÈáëÈ°ç']
    
    # Find the actual column names in the CSV
    date_col = None
    desc_col = None
    amount_col = None
    
    for col in df.columns:
        col_lower = col.lower().strip()
        col_original = col.strip()
        
        # Check English column names
        if col_lower in [name.lower() for name in date_columns]:
            date_col = col
        elif col_lower in [name.lower() for name in desc_columns]:
            desc_col = col
        elif col_lower in [name.lower() for name in amount_columns]:
            amount_col = col
        
        # Check Japanese column names
        if col_original in date_columns:
            date_col = col
        elif col_original in desc_columns:
            desc_col = col
        elif col_original in amount_columns:
            amount_col = col
    
    if not all([date_col, desc_col, amount_col]):
        # If we can't find the expected columns, show available columns and let user choose
        st.warning(f"Could not automatically identify columns. Available columns: {list(df.columns)}")
        st.write("Please select the correct columns:")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            date_col = st.selectbox("Date column:", df.columns, index=0)
        with col2:
            desc_col = st.selectbox("Description column:", df.columns, index=1)
        with col3:
            amount_col = st.selectbox("Amount column:", df.columns, index=2)
    
    # Show column mapping
    st.info(f"Column mapping: Date='{date_col}', Description='{desc_col}', Amount='{amount_col}'")
    
    # Process the data
    transactions = []
    for idx, row in df.iterrows():
        try:
            # Handle different date formats
            date_str = str(row[date_col]).strip()
            if pd.isna(date_str) or date_str == '':
                continue
                
            # Try different date formats (including Japanese format)
            date = None
            date_formats = ['%Y/%m/%d', '%Y-%m-%d', '%d/%m/%Y', '%m/%d/%Y', '%d-%m-%Y', '%Y/%m/%d']
            for fmt in date_formats:
                try:
                    date = datetime.strptime(date_str, fmt)
                    break
                except ValueError:
                    continue
            
            if date is None:
                continue
                
            # Get description and translate if it's Japanese
            description = str(row[desc_col]).strip()
            if pd.isna(description) or description == '':
                continue
            
            # Translate Japanese description to English
            original_description = description
            description = translate_japanese_to_english(description, translation_mode, api_key)
            
            # Show translation progress
            if original_description != description:
                st.info(f"Translated: '{original_description}' ‚Üí '{description}'")
                
            # Handle amount (could be positive or negative)
            amount_str = str(row[amount_col]).strip()
            if pd.isna(amount_str) or amount_str == '':
                continue
                
            # Remove currency symbols, commas, and Japanese characters
            amount_str = re.sub(r'[^\d.-]', '', amount_str)
            amount = float(amount_str)
            
            transactions.append({
                "date": date,
                "description": description,
                "original_description": original_description,  # Keep original for reference
                "amount": amount
            })
            
        except Exception as e:
            st.warning(f"Error processing row {idx + 1}: {row}. Error: {e}")
            continue
    
    if not transactions:
        raise RuntimeError("No valid transactions found in the CSV file.")
    
    st.success(f"Successfully processed {len(transactions)} transactions with Japanese translation!")
    df_result = pd.DataFrame(transactions)
    return df_result
def categorise_transactions(
    df: pd.DataFrame, rules: Dict[str, List[str]], subcategories: Dict[str, Dict[str, List[str]]] = None, 
    uncategorised_label: str = "Uncategorised"
) -> pd.DataFrame:
    """Enhanced categorization with support for main categories and subcategories."""
    
    # Create patterns for main categories
    patterns = {cat: re.compile("(" + "|".join(map(re.escape, kws)) + ")", re.IGNORECASE) for cat, kws in rules.items()}
    
    # Create patterns for subcategories
    sub_patterns = {}
    if subcategories:
        for main_cat, subs in subcategories.items():
            for sub_cat, keywords in subs.items():
                sub_patterns[f"{main_cat}_{sub_cat}"] = {
                    'main': main_cat,
                    'sub': sub_cat,
                    'pattern': re.compile("(" + "|".join(map(re.escape, keywords)) + ")", re.IGNORECASE)
                }
    
    categories = []
    subcategories_list = []
    
    for desc in df["description"].astype(str):
        assigned_category = uncategorised_label
        assigned_subcategory = ""
        
        # First try to match subcategories for more specific categorization
        for sub_key, sub_info in sub_patterns.items():
            if sub_info['pattern'].search(desc):
                assigned_category = sub_info['main']
                assigned_subcategory = sub_info['sub']
                break
        
        # If no subcategory match, try main categories
        if assigned_category == uncategorised_label:
            for cat, pattern in patterns.items():
                if pattern.search(desc):
                    assigned_category = cat
                    break
        
        categories.append(assigned_category)
        subcategories_list.append(assigned_subcategory)
    
    df = df.copy()
    df["category"] = categories
    df["subcategory"] = subcategories_list
    
    return df


def save_custom_rules(rules: Dict[str, List[str]], filename: str = "custom_rules.json") -> None:
    """Save custom categorization rules to a JSON file."""
    import json
    try:
        with open(filename, 'w') as f:
            json.dump(rules, f, indent=2)
        st.success(f"Custom rules saved to {filename}")
    except Exception as e:
        st.error(f"Error saving rules: {e}")

def load_custom_rules(filename: str = "custom_rules.json") -> Dict[str, List[str]]:
    """Load custom categorization rules from a JSON file."""
    import json
    try:
        with open(filename, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        return {}
    except Exception as e:
        st.error(f"Error loading rules: {e}")
        return {}


def main() -> None:
    st.title("Transaction Categoriser")
    st.write(
        "Upload a credit card statement in PDF, CSV, or image format. The app will extract transaction data, "
        "assign categories based on keyword rules and let you review the results."
    )
    
    # AI Translation Setup
    st.sidebar.header("ü§ñ AI Translation Settings")
    st.sidebar.write("For best Japanese translation accuracy, use OpenAI GPT-3.5")
    
    # Check for existing API key
    existing_api_key = os.getenv('OPENAI_API_KEY')
    
    if existing_api_key:
        st.sidebar.success("‚úÖ OpenAI API key found in environment")
        api_key = existing_api_key
    else:
        # API Key input
        api_key = st.sidebar.text_input(
            "OpenAI API Key", 
            type="password",
            help="Get your API key from https://platform.openai.com/api-keys (same account as ChatGPT Premium)"
        )
        
        if api_key:
            st.sidebar.success("‚úÖ API key configured for this session")
            # Set environment variable for this session
            os.environ['OPENAI_API_KEY'] = api_key
    
    # Quick setup guide for ChatGPT Premium users
    if not api_key:
        with st.sidebar.expander("üöÄ Quick Setup for ChatGPT Premium Users"):
            st.write("""
            1. **Go to:** https://platform.openai.com/api-keys
            2. **Sign in** with your ChatGPT Premium account
            3. **Click "Create new secret key"**
            4. **Copy the key** (starts with `sk-...`)
            5. **Paste it above** for AI-powered Japanese translation
            """)
            st.info("üí° Your ChatGPT Premium account gives you access to the API!")
    
    # Translation mode selection
    if api_key:
        translation_mode = st.sidebar.selectbox(
            "Translation Mode",
            ["Free Fallback", "AI-Powered (GPT-3.5)", "No Translation"],
            index=0,  # Default to Free Fallback
            help="Free Fallback uses Google Translate, AI-Powered uses OpenAI for better accuracy"
        )
    else:
        translation_mode = "Free Fallback"
        st.sidebar.info("‚ÑπÔ∏è Using free translation (enter API key for AI accuracy)")
    
    # File upload
    uploaded_file = st.file_uploader("Choose a statement file", 
type=["pdf", "png", "jpg", "jpeg", "csv"])
    if uploaded_file is not None:
        try:
            if uploaded_file.type == "application/pdf":
                df = extract_transactions_from_pdf(uploaded_file)
            elif uploaded_file.type == "text/csv":
                df = extract_transactions_from_csv(uploaded_file, translation_mode, api_key)
            else:
                df = extract_transactions_from_image(uploaded_file)
        except Exception as e:
            st.error(f"Error processing file: {e}")
            return
        st.success(f"Loaded {len(df)} transactions.")
        # MoneyMgr Proven Categorization System (Based on 3,943+ real transactions)
        rules = {
            "Food": [
                # Groceries and Food Stores
                "„É≠„Éº„ÇΩ„É≥", "„Çª„Éñ„É≥„Ç§„É¨„Éñ„É≥", "„Éï„Ç°„Éü„É™„Éº„Éû„Éº„Éà", "„Ç≥„É≥„Éì„Éã", "lawson", "seven eleven", "family mart",
                "„Éù„Éó„É©„Ç∞„É´„Éº„Éó", "poplar", "„Çπ„Éº„Éë„Éº", "supermarket", "grocery", "market", "food", "fresh",
                "„Ç§„Ç™„É≥", "aeon", "„Ç§„Éà„Éº„É®„Éº„Ç´„Éâ„Éº", "itoyokado", "Ë•øÂèã", "seiyu", "„É©„Ç§„Éï", "life",
                # Restaurants and Dining
                "„É¨„Çπ„Éà„É©„É≥", "restaurant", "cafe", "dinner", "lunch", "breakfast", "takeaway", "delivery",
                "Â±ÖÈÖíÂ±ã", "izakaya", "„Éê„Éº", "bar", "„Ç´„Éï„Çß", "coffee", "„Éî„Ç∂", "pizza", "ÂØøÂè∏", "sushi",
                "„Éû„ÇØ„Éâ„Éä„É´„Éâ", "mcdonalds", "„Ç±„É≥„Çø„ÉÉ„Ç≠„Éº", "kfc", "„Çπ„Çø„Éº„Éê„ÉÉ„ÇØ„Çπ", "starbucks"
            ],
            "Social Life": [
                # Social Activities
                "È£≤„Åø‰ºö", "drinking", "„Éë„Éº„ÉÜ„Ç£„Éº", "party", "„Ç§„Éô„É≥„Éà", "event", "ÂèãÈÅî", "friend", "ÂêåÂÉö", "colleague",
                "‰ºöÈ£ü", "dining", "ÊááË¶™‰ºö", "networking", "Ê≠ìËøé‰ºö", "welcome", "ÈÄÅÂà•‰ºö", "farewell",
                "„Ç´„É©„Ç™„Ç±", "karaoke", "„Éú„Éº„É™„É≥„Ç∞", "bowling", "„Ç≤„Éº„É†", "game", "„Çπ„Éù„Éº„ÉÑ", "sports"
            ],
            "Subscriptions": [
                # Digital Services
                "icloud", "apple music", "amazon prime", "google one", "netflix", "spotify", "hulu", "disney+",
                "„Ç¢„Éû„Çæ„É≥„Éó„É©„Ç§„É†", "„Ç∞„Éº„Ç∞„É´„ÉØ„É≥", "„Ç¢„ÉÉ„Éó„É´„Éü„É•„Éº„Ç∏„ÉÉ„ÇØ", "„Ç¢„Ç§„ÇØ„É©„Ç¶„Éâ",
                "subscription", "membership", "ÊúàÈ°ç", "monthly", "Âπ¥È°ç", "annual"
            ],
            "Household": [
                # Home and Living
                "ÂÆ∂Ë≥É", "rent", "ÂÖâÁÜ±Ë≤ª", "utility", "ÈõªÊ∞ó", "electric", "„Ç¨„Çπ", "gas", "Ê∞¥ÈÅì", "water",
                "ÂÆ∂ÂÖ∑", "furniture", "ÂÆ∂Èõª", "appliance", "Êó•Áî®ÂìÅ", "daily", "ÊéÉÈô§", "cleaning",
                "„Éã„Éà„É™", "nitori", "„Ç§„Ç±„Ç¢", "ikea", "„Éõ„Éº„É†„Çª„É≥„Çø„Éº", "home center"
            ],
            "Transportation": [
                # Public Transport and Travel
                "ÈõªËªä", "train", "„Éê„Çπ", "bus", "„Çø„ÇØ„Ç∑„Éº", "taxi", "Âú∞‰∏ãÈâÑ", "subway", "„É¢„Éé„É¨„Éº„É´", "monorail",
                "„É¢„Éê„Ç§„É´„Éë„Çπ", "mobile pass", "‰∫§ÈÄöË≤ª", "transport", "ÈßêËªäÂ†¥", "parking", "È´òÈÄüÈÅìË∑Ø", "highway",
                "Ôº•Ôº¥Ôº£", "etc", "„Ç¨„ÇΩ„É™„É≥", "gasoline", "ÁáÉÊñô", "fuel", "Ëªä", "car", "„Éê„Ç§„ÇØ", "bike"
            ],
            "Vacation": [
                # Travel and Leisure
                "ÊóÖË°å", "travel", "„Éõ„ÉÜ„É´", "hotel", "È£õË°åÊ©ü", "flight", "Êñ∞ÂππÁ∑ö", "shinkansen", "Ë¶≥ÂÖâ", "tourism",
                "Ê∏©Ê≥â", "onsen", "„É™„Çæ„Éº„Éà", "resort", "„Éì„Éº„ÉÅ", "beach", "Â±±", "mountain", "Êµ∑", "sea",
                "„ÉÅ„Ç±„ÉÉ„Éà", "ticket", "„ÉÑ„Ç¢„Éº", "tour", "ÂÆøÊ≥ä", "accommodation"
            ],
            "Health": [
                # Healthcare and Wellness
                "ÁóÖÈô¢", "hospital", "„ÇØ„É™„Éã„ÉÉ„ÇØ", "clinic", "Ê≠ØÁßë", "dental", "ÁúºÁßë", "eye", "Ëñ¨Â±Ä", "pharmacy",
                "Ëñ¨", "medicine", "‰øùÈô∫", "insurance", "Ë®∫ÂØü", "examination", "Ê≤ªÁôÇ", "treatment",
                "„Éï„Ç£„ÉÉ„Éà„Éç„Çπ", "fitness", "„Ç∏„É†", "gym", "„É®„Ç¨", "yoga", "„Éû„ÉÉ„Çµ„Éº„Ç∏", "massage"
            ],
            "Apparel": [
                # Clothing and Fashion
                "Êúç", "clothing", "Èù¥", "shoes", "„Éê„ÉÉ„Ç∞", "bag", "„Ç¢„ÇØ„Çª„Çµ„É™„Éº", "accessory", "ÊôÇË®à", "watch",
                "„É¶„Éã„ÇØ„É≠", "uniqlo", "zara", "h&m", "gap", "nike", "adidas", "„Ç¢„Éá„Ç£„ÉÄ„Çπ", "„Éä„Ç§„Ç≠",
                "„Éï„Ç°„ÉÉ„Ç∑„Éß„É≥", "fashion", "„Çπ„Çø„Ç§„É´", "style", "„Éñ„É©„É≥„Éâ", "brand"
            ],
            "Grooming": [
                # Personal Care
                "ÁæéÂÆπ", "beauty", "ÂåñÁ≤ßÂìÅ", "cosmetics", "„Çπ„Ç≠„É≥„Ç±„Ç¢", "skincare", "„Éò„Ç¢„Ç±„Ç¢", "haircare",
                "„Éç„Ç§„É´", "nail", "„Ç®„Çπ„ÉÜ", "esthetic", "ÁêÜÂÆπ", "barber", "ÁæéÂÆπÈô¢", "salon",
                "Ë≥áÁîüÂ†Ç", "shiseido", "„Éù„Éº„É©", "pola", "„Éï„Ç°„É≥„Ç±„É´", "fancl"
            ],
            "Self-development": [
                # Education and Growth
                "Êú¨", "book", "ÈõëË™å", "magazine", "Êñ∞ËÅû", "newspaper", "Ë¨õÂ∫ß", "course", "„Çª„Éü„Éä„Éº", "seminar",
                "„ÉØ„Éº„ÇØ„Ç∑„Éß„ÉÉ„Éó", "workshop", "Ë≥áÊ†º", "certification", "Â≠¶Áøí", "learning", "„Çπ„Ç≠„É´", "skill",
                "„Ç™„É≥„É©„Ç§„É≥", "online", "e„É©„Éº„Éã„É≥„Ç∞", "elearning", "„Éà„É¨„Éº„Éã„É≥„Ç∞", "training"
            ]
        }
        
        # MoneyMgr Subcategory System for Detailed Breakdown
        subcategories = {
            "Food": {
                "Groceries": ["„É≠„Éº„ÇΩ„É≥", "„Çª„Éñ„É≥„Ç§„É¨„Éñ„É≥", "„Éï„Ç°„Éü„É™„Éº„Éû„Éº„Éà", "„Ç≥„É≥„Éì„Éã", "„Çπ„Éº„Éë„Éº", "„Éù„Éó„É©„Ç∞„É´„Éº„Éó"],
                "Dinner/Eating Out": ["„É¨„Çπ„Éà„É©„É≥", "Â±ÖÈÖíÂ±ã", "„Éê„Éº", "dinner", "restaurant", "izakaya"],
                "Lunch/Eating Out": ["lunch", "„Ç´„Éï„Çß", "coffee", "ÊòºÈ£ü", "„É©„É≥„ÉÅ"],
                "Beverages A": ["„Çπ„Çø„Éº„Éê„ÉÉ„ÇØ„Çπ", "„Ç≥„Éº„Éí„Éº", "tea", "„Ç∏„É•„Éº„Çπ", "drink"],
                "Beverages/Non-A": ["„Ç¢„É´„Ç≥„Éº„É´", "ÈÖí", "„Éì„Éº„É´", "wine", "spirits"]
            },
            "Social Life": {
                "Drinking": ["È£≤„Åø‰ºö", "drinking", "„Éë„Éº„ÉÜ„Ç£„Éº", "party", "„Ç´„É©„Ç™„Ç±", "karaoke"],
                "Event": ["„Ç§„Éô„É≥„Éà", "event", "‰ºöÈ£ü", "dining", "ÊááË¶™‰ºö", "networking"],
                "Friend": ["ÂèãÈÅî", "friend", "ÂêåÂÉö", "colleague", "Ê≠ìËøé‰ºö", "ÈÄÅÂà•‰ºö"]
            },
            "Transportation": {
                "Subway": ["Âú∞‰∏ãÈâÑ", "subway", "ÈõªËªä", "train", "„É¢„Éé„É¨„Éº„É´", "monorail"],
                "Taxi": ["„Çø„ÇØ„Ç∑„Éº", "taxi", "Ëªä", "car", "„É©„Ç§„Éâ„Ç∑„Çß„Ç¢", "rideshare"],
                "Mobile Pass": ["„É¢„Éê„Ç§„É´„Éë„Çπ", "mobile pass", "‰∫§ÈÄöË≤ª", "transport"],
                "ETC": ["Ôº•Ôº¥Ôº£", "etc", "È´òÈÄüÈÅìË∑Ø", "highway", "ÈßêËªäÂ†¥", "parking"]
            },
            "Household": {
                "Rent": ["ÂÆ∂Ë≥É", "rent", "‰ΩèÂÆÖË≤ª", "housing"],
                "Utilities": ["ÂÖâÁÜ±Ë≤ª", "utility", "ÈõªÊ∞ó", "electric", "„Ç¨„Çπ", "gas", "Ê∞¥ÈÅì", "water"],
                "Furniture": ["ÂÆ∂ÂÖ∑", "furniture", "„Éã„Éà„É™", "nitori", "„Ç§„Ç±„Ç¢", "ikea"]
            }
        }
        df_cat = categorise_transactions(df, rules, subcategories)
        
        # Smart categorization interface
        st.subheader("üéØ Smart Transaction Categorization")
        
        # Get all available categories and subcategories
        all_categories = list(rules.keys()) + ["Uncategorised"]
        all_subcategories = []
        for main_cat, subs in subcategories.items():
            for sub_cat in subs.keys():
                all_subcategories.append(f"{main_cat} - {sub_cat}")
        
        # Show categorization statistics
        category_counts = df_cat['category'].value_counts()
        st.info(f"üìä **Categorization Summary:** {len(df_cat)} total transactions")
        
        # Display category breakdown with subcategories
        col1, col2 = st.columns(2)
        with col1:
            st.write("**Main Categories:**")
            for cat, count in category_counts.items():
                if cat != "Uncategorised":
                    st.write(f"‚Ä¢ {cat}: {count}")
                    
                    # Show subcategories for this main category
                    if cat in subcategories:
                        sub_counts = df_cat[df_cat['category'] == cat]['subcategory'].value_counts()
                        for sub_cat, sub_count in sub_counts.items():
                            if sub_cat:  # Only show non-empty subcategories
                                st.write(f"  ‚îî‚îÄ {sub_cat}: {sub_count}")
        
        with col2:
            uncategorized_count = category_counts.get("Uncategorised", 0)
            st.write(f"**Uncategorized:** {uncategorized_count}")
            
            # Show total transactions
            st.write(f"**Total Transactions:** {len(df_cat)}")
        
        # Smart categorization for uncategorized transactions
        if uncategorized_count > 0:
            st.subheader("üöÄ Quick Categorization")
            st.write("Use the dropdowns below to quickly categorize uncategorized transactions:")
            
            # Get uncategorized transactions
            uncategorized_df = df_cat[df_cat['category'] == 'Uncategorised'].copy()
            
            # Create a form for bulk categorization
            with st.form("bulk_categorization"):
                # Suggest categories based on description keywords
                for idx, row in uncategorized_df.iterrows():
                    description = str(row['description']).lower()
                    original_desc = str(row.get('original_description', '')).lower()
                    
                    # Smart category suggestions based on keywords
                    suggested_category = "Uncategorised"
                    for category, keywords in rules.items():
                        if any(keyword.lower() in description or keyword.lower() in original_desc for keyword in keywords):
                            suggested_category = category
                            break
                    
                    # Special handling for common Japanese merchants
                    if any(word in original_desc for word in ['„É≠„Éº„ÇΩ„É≥', '„Çª„Éñ„É≥„Ç§„É¨„Éñ„É≥', '„Éï„Ç°„Éü„Éû', '„Ç≥„É≥„Éì„Éã']):
                        suggested_category = "Groceries"
                    elif any(word in original_desc for word in ['„Éã„Éà„É™', '„Ç§„Ç±„Ç¢', 'ÂÆ∂ÂÖ∑']):
                        suggested_category = "Shopping & Retail"
                    elif any(word in original_desc for word in ['„Ç¢„Éû„Çæ„É≥', 'amazon']):
                        suggested_category = "Shopping & Retail"
                    elif any(word in original_desc for word in ['„É¢„Éê„Ç§„É´„Éë„Çπ', '‰∫§ÈÄö']):
                        suggested_category = "Transportation"
                    
                    col1, col2, col3 = st.columns([3, 2, 1])
                    with col1:
                        st.write(f"**{row['description'][:50]}...**")
                    with col2:
                        new_category = st.selectbox(
                            f"Category for {row['description'][:30]}...",
                            all_categories,
                            index=all_categories.index(suggested_category),
                            key=f"cat_{idx}"
                        )
                    with col3:
                        st.write(f"¬•{row['amount']:,}")
                    
                    # Update the category
                    df_cat.loc[idx, 'category'] = new_category
                
                submitted = st.form_submit_button("‚úÖ Apply All Categorizations")
                if submitted:
                    st.success("üéâ All categories updated! Scroll down to see the results.")
        
        # Show the final categorized data
        st.subheader("üìã Review All Transactions")
        st.write("Final categorized transactions (you can still edit individual categories):")
        
        # Use data editor for final review
        edited_df = st.data_editor(df_cat, num_rows="dynamic")
        
        if not edited_df.empty:
            edited_df["month"] = pd.to_datetime(edited_df["date"]).dt.to_period("M").astype(str)
            summary = (
                edited_df.groupby(["month", "category"])["amount"].sum().reset_index(name="total_amount")
            )
            st.subheader("üìä Monthly Summary")
            st.write(summary)
            pivot = summary.pivot(index="month", columns="category", values="total_amount").fillna(0)
            st.bar_chart(pivot)


if __name__ == "__main__":
    main()

