#!/usr/bin/env python3
"""
Simple Bank Statement Analyzer

A lightweight version that works with basic Python libraries to analyze
and cross-check bank statements without external dependencies.
"""

import csv
import json
import re
from datetime import datetime
from collections import defaultdict, Counter
import os

class SimpleBankAnalyzer:
    """Simple bank statement analyzer using only standard library."""
    
    def __init__(self):
        self.csv_data = []
        self.pdf_data = []
        self.categorization_rules = {
            "Food & Groceries": [
                "ãƒ­ãƒ¼ã‚½ãƒ³", "ã‚»ãƒ–ãƒ³ã‚¤ãƒ¬ãƒ–ãƒ³", "ãƒ•ã‚¡ãƒŸãƒªãƒ¼ãƒãƒ¼ãƒˆ", "ã‚³ãƒ³ãƒ“ãƒ‹", "lawson", "seven eleven", "family mart",
                "ãƒãƒ—ãƒ©ã‚°ãƒ«ãƒ¼ãƒ—", "poplar", "ã‚¹ãƒ¼ãƒ‘ãƒ¼", "supermarket", "grocery", "market", "food", "fresh",
                "ã‚¤ã‚ªãƒ³", "aeon", "ã‚¤ãƒˆãƒ¼ãƒ¨ãƒ¼ã‚«ãƒ‰ãƒ¼", "itoyokado", "è¥¿å‹", "seiyu", "ãƒ©ã‚¤ãƒ•", "life",
                "ãƒ‰ãƒ³ã‚­ãƒ›ãƒ¼ãƒ†", "ãƒãƒ¼ã‚¬ãƒ¼ã‚­ãƒ³ã‚°", "ã‚¤ãƒ¼ã‚¸ãƒ¼ã‚ºã‚«ãƒ•ã‚§", "ã‚µã‚«ãƒ‰ãƒ¤", "ã‚¨ãƒŒã‚·ãƒ¼ãƒ‡ã‚¤",
                "ãƒãƒŠãƒãƒ«ã‚­", "ãƒãƒŠã‚³ã‚¦ã‚¸ãƒ§ã‚¦", "ã‚µã‚¦ãƒŠæ±äº¬", "ãƒãƒ«ã‚¨ãƒ„", "ãƒãƒ„ãƒãƒ¤ãƒ¨ã‚¦ã‚¬",
                "ã‚¬ãƒ³ã‚½ã‚ºã‚·", "ãƒãƒ«ã‚¬ãƒ¡ã‚»ã‚¤ãƒ¡ãƒ³", "ã‚«ãƒ–ã‚·ã‚­ã‚¬ã‚¤ã‚·ãƒ£", "ã‚µãƒ³ãƒˆãƒ©ãƒƒã‚¯", "ãƒãƒ–ãƒ«ãƒã‚¦ã‚¹"
            ],
            "Transportation": [
                "é›»è»Š", "train", "ãƒã‚¹", "bus", "ã‚¿ã‚¯ã‚·ãƒ¼", "taxi", "åœ°ä¸‹é‰„", "subway", "ãƒ¢ãƒãƒ¬ãƒ¼ãƒ«", "monorail",
                "ãƒ¢ãƒã‚¤ãƒ«ãƒ‘ã‚¹", "mobile pass", "äº¤é€šè²»", "transport", "é§è»Šå ´", "parking", "é«˜é€Ÿé“è·¯", "highway",
                "ï¼¥ï¼´ï¼£", "etc", "ã‚¬ã‚½ãƒªãƒ³", "gasoline", "ç‡ƒæ–™", "fuel", "è»Š", "car", "ãƒã‚¤ã‚¯", "bike",
                "ï¼¥ï¼®ï¼¥ï¼¯ï¼³", "ENEOS", "ã‚¬ã‚½ãƒªãƒ³ã‚¹ã‚¿ãƒ³ãƒ‰", "gas station"
            ],
            "Shopping & Retail": [
                "AMAZON", "amazon", "ã‚¢ãƒã‚¾ãƒ³", "æ¥½å¤©", "rakuten", "ãƒ¤ãƒ•ãƒ¼", "yahoo",
                "ãƒ‹ãƒˆãƒª", "nitori", "ã‚¤ã‚±ã‚¢", "ikea", "ãƒ›ãƒ¼ãƒ ã‚»ãƒ³ã‚¿ãƒ¼", "home center", "å®¶å…·", "furniture",
                "ãƒ¦ãƒ‹ã‚¯ãƒ­", "uniqlo", "zara", "h&m", "gap", "nike", "adidas", "ã‚¢ãƒ‡ã‚£ãƒ€ã‚¹", "ãƒŠã‚¤ã‚­",
                "ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³", "fashion", "ã‚¹ã‚¿ã‚¤ãƒ«", "style", "ãƒ–ãƒ©ãƒ³ãƒ‰", "brand",
                "ãƒã‚±ãƒƒãƒˆã‚¸ãƒ£ãƒ ", "ãƒ­ã‚³ãƒãƒ­ã‚¤", "ãƒã‚¯ãƒ†ã‚¤ãƒ—ãƒ©ã‚¶", "ãƒãƒ«ã‚¤ãƒ•ã‚¡", "æ±äº¬ãƒŸãƒƒãƒ‰ã‚¿ã‚¦ãƒ³",
                "æ–°ãƒãƒ«ãƒã‚¦ãƒãƒ“ãƒ«", "ã‚¿ã‚¤ãƒ ã‚ºã‚«ãƒ¼", "ã‚¤ãƒ‡ãƒŸãƒ„", "ã‚¢ãƒãƒ­ã‚¹ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³"
            ],
            "Subscriptions & Services": [
                "OPENAI", "CHATGPT", "icloud", "apple music", "amazon prime", "google one", 
                "netflix", "spotify", "hulu", "disney+", "ã‚¢ãƒã‚¾ãƒ³ãƒ—ãƒ©ã‚¤ãƒ ", "ã‚°ãƒ¼ã‚°ãƒ«ãƒ¯ãƒ³",
                "ã‚¢ãƒƒãƒ—ãƒ«ãƒŸãƒ¥ãƒ¼ã‚¸ãƒƒã‚¯", "ã‚¢ã‚¤ã‚¯ãƒ©ã‚¦ãƒ‰", "subscription", "membership", "æœˆé¡", "monthly", "å¹´é¡", "annual",
                "æ¥½å¤©ãƒ¢ãƒã‚¤ãƒ«", "rakuten mobile", "é€šä¿¡æ–™", "communication", "é›»è©±", "phone",
                "æ¥½å¤©ã§ã‚“ã", "rakuten electricity", "æ¥½å¤©ã‚¬ã‚¹", "rakuten gas", "é›»æ°—", "electric", "ã‚¬ã‚¹", "gas"
            ],
            "Entertainment & Recreation": [
                "ã‚¤ãƒ™ãƒ³ãƒˆã‚´ãƒªãƒ§ã‚¦ãƒ–ãƒ³", "event", "ã‚¤ãƒ™ãƒ³ãƒˆ", "ã‚³ãƒ³ã‚µãƒ¼ãƒˆ", "concert", "æ˜ ç”»", "movie",
                "ã‚²ãƒ¼ãƒ ", "game", "ã‚¹ãƒãƒ¼ãƒ„", "sports", "ã‚«ãƒ©ã‚ªã‚±", "karaoke", "ãƒœãƒ¼ãƒªãƒ³ã‚°", "bowling",
                "ã‚¾ã‚¾ãƒãƒªãƒ³ã‚¹ã‚¿ã‚¸ã‚¢ãƒ ", "ãƒãƒŠãƒãƒ«ã‚¦ãƒ‰ãƒ³", "ãƒŸãƒ‹ã‚¹ãƒˆãƒƒãƒ—", "ã‚¤ãƒ™ãƒ³ãƒˆã‚´ãƒªãƒ§ã‚¦ãƒ–ãƒ³"
            ],
            "Health & Wellness": [
                "ç—…é™¢", "hospital", "ã‚¯ãƒªãƒ‹ãƒƒã‚¯", "clinic", "æ­¯ç§‘", "dental", "çœ¼ç§‘", "eye", "è–¬å±€", "pharmacy",
                "è–¬", "medicine", "ä¿é™º", "insurance", "è¨ºå¯Ÿ", "examination", "æ²»ç™‚", "treatment",
                "ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹", "fitness", "ã‚¸ãƒ ", "gym", "ãƒ¨ã‚¬", "yoga", "ãƒãƒƒã‚µãƒ¼ã‚¸", "massage"
            ],
            "Fees & Charges": [
                "æ‰‹æ•°æ–™", "fee", "å¹´ä¼šè²»", "annual fee", "åˆ©ç”¨æ–™", "usage fee", "ï¼¡ï¼´ï¼­", "ATM",
                "æ”¯æ‰•æ‰‹æ•°æ–™", "payment fee", "ç¾åœ°åˆ©ç”¨é¡", "local usage", "å¤‰æ›ãƒ¬ãƒ¼ãƒˆ", "exchange rate"
            ],
            "Cash & ATM": [
                "ãƒ­ãƒ¼ã‚½ãƒ³éŠ€è¡Œ", "lawson bank", "ï¼£ï¼¤", "CD", "ç¾é‡‘", "cash", "å¼•ãå‡ºã—", "withdrawal"
            ]
        }
    
    def parse_csv_file(self, file_path):
        """Parse CSV bank statement file."""
        print(f"ğŸ“„ Parsing CSV file: {file_path}")
        
        with open(file_path, 'r', encoding='utf-8-sig') as file:  # Use utf-8-sig to handle BOM
            reader = csv.DictReader(file)
            
            # Debug: print column names
            print(f"Column names: {reader.fieldnames}")
            
            for row_num, row in enumerate(reader, 1):
                # Handle the BOM issue with the first column
                date_key = None
                for key in row.keys():
                    if 'åˆ©ç”¨æ—¥' in key:
                        date_key = key
                        break
                
                if not date_key or not row.get('åˆ©ç”¨åº—åãƒ»å•†å“å') or not row.get('åˆ©ç”¨é‡‘é¡'):
                    continue
                
                try:
                    # Parse date - remove quotes and strip
                    date_str = row[date_key].strip().strip('"')
                    if re.match(r'\d{4}/\d{2}/\d{2}', date_str):
                        date = datetime.strptime(date_str, '%Y/%m/%d')
                    else:
                        continue
                    
                    # Parse amount - remove quotes and clean
                    amount_str = row['åˆ©ç”¨é‡‘é¡'].strip().strip('"')
                    amount = float(re.sub(r'[^\d.-]', '', amount_str))
                    
                    # Skip zero amounts
                    if amount == 0:
                        continue
                    
                    # Create transaction record
                    transaction = {
                        'date': date,
                        'description': row['åˆ©ç”¨åº—åãƒ»å•†å“å'].strip().strip('"'),
                        'amount': amount,
                        'user': row.get('åˆ©ç”¨è€…', '').strip().strip('"'),
                        'payment_method': row.get('æ”¯æ‰•æ–¹æ³•', '').strip().strip('"'),
                        'fee': float(re.sub(r'[^\d.-]', '', row.get('æ”¯æ‰•æ‰‹æ•°æ–™', '0').strip().strip('"'))),
                        'total_amount': float(re.sub(r'[^\d.-]', '', row.get('æ”¯æ‰•ç·é¡', '0').strip().strip('"'))),
                        'source': 'CSV'
                    }
                    
                    self.csv_data.append(transaction)
                    
                except (ValueError, KeyError) as e:
                    print(f"âš ï¸ Skipping invalid row {row_num}: {e}")
                    continue
        
        print(f"âœ… Parsed {len(self.csv_data)} transactions from CSV")
        return self.csv_data
    
    def categorize_transaction(self, description):
        """Categorize a transaction based on description."""
        description_lower = description.lower()
        
        for category, keywords in self.categorization_rules.items():
            for keyword in keywords:
                if keyword.lower() in description_lower:
                    return category
        
        return "Uncategorised"
    
    def analyze_data(self, data):
        """Analyze transaction data and return summary statistics."""
        if not data:
            return {}
        
        # Basic statistics
        total_amount = sum(t['amount'] for t in data)
        transaction_count = len(data)
        
        # Date range
        dates = [t['date'] for t in data]
        min_date = min(dates)
        max_date = max(dates)
        
        # Categorization
        categories = defaultdict(list)
        for transaction in data:
            category = self.categorize_transaction(transaction['description'])
            categories[category].append(transaction)
        
        # Category summaries
        category_summary = {}
        for category, transactions in categories.items():
            category_summary[category] = {
                'count': len(transactions),
                'total_amount': sum(t['amount'] for t in transactions),
                'avg_amount': sum(t['amount'] for t in transactions) / len(transactions) if transactions else 0
            }
        
        return {
            'transaction_count': transaction_count,
            'total_amount': total_amount,
            'date_range': f"{min_date.strftime('%Y-%m-%d')} to {max_date.strftime('%Y-%m-%d')}",
            'categories': category_summary,
            'duplicates': self.find_duplicates(data)
        }
    
    def find_duplicates(self, data):
        """Find duplicate transactions."""
        seen = set()
        duplicates = []
        
        for transaction in data:
            key = (transaction['date'], transaction['description'], transaction['amount'])
            if key in seen:
                duplicates.append(transaction)
            else:
                seen.add(key)
        
        return duplicates
    
    def cross_check_data(self, csv_data, pdf_data):
        """Cross-check CSV and PDF data for discrepancies."""
        print("ğŸ” Cross-checking CSV and PDF data...")
        
        # Create comparison keys
        csv_keys = set()
        for t in csv_data:
            key = f"{t['date'].strftime('%Y-%m-%d')}|{t['description']}|{t['amount']}"
            csv_keys.add(key)
        
        pdf_keys = set()
        for t in pdf_data:
            key = f"{t['date'].strftime('%Y-%m-%d')}|{t['description']}|{t['amount']}"
            pdf_keys.add(key)
        
        # Find differences
        only_in_csv = csv_keys - pdf_keys
        only_in_pdf = pdf_keys - csv_keys
        common = csv_keys & pdf_keys
        
        # Calculate totals
        csv_total = sum(t['amount'] for t in csv_data)
        pdf_total = sum(t['amount'] for t in pdf_data)
        difference = abs(csv_total - pdf_total)
        
        return {
            'csv_total': csv_total,
            'pdf_total': pdf_total,
            'difference': difference,
            'only_in_csv': len(only_in_csv),
            'only_in_pdf': len(only_in_pdf),
            'common': len(common),
            'reconciliation_status': 'reconciled' if difference < 1000 else 'discrepancy'
        }
    
    def generate_report(self, csv_analysis, pdf_analysis, cross_check):
        """Generate comprehensive analysis report."""
        report = []
        report.append("# Bank Statement Analysis Report")
        report.append(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # Summary
        report.append("## Summary")
        report.append(f"- CSV Transactions: {csv_analysis['transaction_count']} | Total: Â¥{csv_analysis['total_amount']:,.0f}")
        if pdf_analysis:
            report.append(f"- PDF Transactions: {pdf_analysis['transaction_count']} | Total: Â¥{pdf_analysis['total_amount']:,.0f}")
        report.append(f"- Reconciliation Status: {cross_check['reconciliation_status']}")
        report.append(f"- Total Difference: Â¥{cross_check['difference']:,.0f}")
        report.append("")
        
        # CSV Analysis
        report.append("## CSV Statement Analysis")
        report.append(f"- **Total Transactions:** {csv_analysis['transaction_count']}")
        report.append(f"- **Total Amount:** Â¥{csv_analysis['total_amount']:,.0f}")
        report.append(f"- **Date Range:** {csv_analysis['date_range']}")
        report.append(f"- **Duplicates Found:** {len(csv_analysis['duplicates'])}")
        report.append("")
        
        # Category breakdown
        report.append("### Category Breakdown")
        for category, stats in csv_analysis['categories'].items():
            report.append(f"- **{category}**: {stats['count']} transactions, Â¥{stats['total_amount']:,.0f} (avg: Â¥{stats['avg_amount']:,.0f})")
        report.append("")
        
        # Cross-check results
        if cross_check:
            report.append("## Cross-Check Results")
            report.append(f"- **CSV Total:** Â¥{cross_check['csv_total']:,.0f}")
            if pdf_analysis:
                report.append(f"- **PDF Total:** Â¥{cross_check['pdf_total']:,.0f}")
            report.append(f"- **Difference:** Â¥{cross_check['difference']:,.0f}")
            report.append(f"- **Only in CSV:** {cross_check['only_in_csv']} transactions")
            if pdf_analysis:
                report.append(f"- **Only in PDF:** {cross_check['only_in_pdf']} transactions")
            report.append(f"- **Common:** {cross_check['common']} transactions")
            report.append("")
        
        # Recommendations
        report.append("## Recommendations")
        if cross_check['reconciliation_status'] == 'discrepancy':
            report.append("- âš ï¸ **Discrepancy detected** - Review both statements carefully")
            report.append("- Check for missing transactions in either source")
            report.append("- Verify transaction amounts and dates")
        else:
            report.append("- âœ… **Statements are reconciled** - Data integrity is good")
        
        if csv_analysis['duplicates']:
            report.append(f"- âš ï¸ **{len(csv_analysis['duplicates'])} duplicate transactions found** - Review and remove if necessary")
        
        report.append("- Review uncategorized transactions and add rules if needed")
        report.append("- Consider setting up automated reconciliation for future statements")
        
        return "\n".join(report)
    
    def export_categorized_data(self, data, filename):
        """Export categorized data to CSV."""
        print(f"ğŸ“¥ Exporting categorized data to {filename}")
        
        # Add categories to data
        for transaction in data:
            transaction['category'] = self.categorize_transaction(transaction['description'])
        
        # Write to CSV
        with open(filename, 'w', newline='', encoding='utf-8') as file:
            if data:
                fieldnames = data[0].keys()
                writer = csv.DictWriter(file, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(data)
        
        print(f"âœ… Exported {len(data)} transactions to {filename}")


def main():
    """Main function to run the bank statement analyzer."""
    analyzer = SimpleBankAnalyzer()
    
    # File paths
    csv_path = "/workspace/temp_repo/bank/statements/enavi202509(5734) (2).csv"
    
    print("ğŸ¦ Bank Statement Analyzer")
    print("=" * 50)
    
    try:
        # Parse CSV data
        csv_data = analyzer.parse_csv_file(csv_path)
        
        if not csv_data:
            print("âŒ No data found in CSV file")
            return
        
        # Analyze CSV data
        print("\nğŸ“Š Analyzing CSV data...")
        csv_analysis = analyzer.analyze_data(csv_data)
        
        # Cross-check (simplified - no PDF parsing for now)
        print("\nğŸ” Running analysis...")
        cross_check = {
            'csv_total': csv_analysis['total_amount'],
            'pdf_total': 0,  # No PDF data for now
            'difference': csv_analysis['total_amount'],
            'only_in_csv': csv_analysis['transaction_count'],
            'only_in_pdf': 0,
            'common': 0,
            'reconciliation_status': 'csv_only'
        }
        
        # Generate report
        print("\nğŸ“ Generating report...")
        report = analyzer.generate_report(csv_analysis, None, cross_check)
        
        # Save report
        with open("/workspace/bank_analysis_report.md", "w", encoding="utf-8") as f:
            f.write(report)
        
        print("âœ… Analysis complete!")
        print(f"ğŸ“„ Report saved to: /workspace/bank_analysis_report.md")
        
        # Export categorized data
        analyzer.export_categorized_data(csv_data, "/workspace/categorized_transactions.csv")
        print(f"ğŸ“Š Categorized data saved to: /workspace/categorized_transactions.csv")
        
        # Print summary
        print("\n" + "="*50)
        print("SUMMARY")
        print("="*50)
        print(f"CSV Transactions: {csv_analysis['transaction_count']} | Total: Â¥{csv_analysis['total_amount']:,.0f}")
        print(f"Date Range: {csv_analysis['date_range']}")
        print(f"Duplicates: {len(csv_analysis['duplicates'])}")
        print(f"Categories: {len(csv_analysis['categories'])}")
        
        # Show top categories
        print("\nTop Categories by Amount:")
        sorted_categories = sorted(csv_analysis['categories'].items(), 
                                 key=lambda x: x[1]['total_amount'], reverse=True)
        for category, stats in sorted_categories[:5]:
            print(f"  {category}: Â¥{stats['total_amount']:,.0f} ({stats['count']} transactions)")
        
    except Exception as e:
        print(f"âŒ Analysis failed: {e}")
        raise


if __name__ == "__main__":
    main()